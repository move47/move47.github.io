I"h<p><img src="https://martiansideofthemoon.github.io/assets/hurdles_naacl.png" alt="hurdles_naacl" /></p>

<p>This is a project page for our <a href="https://2021.naacl.org/">NAACL 2021</a> paper on long-form question answering. For more details, contact me at <a href="mailto:kalpesh@cs.umass.edu">kalpesh@cs.umass.edu</a>.</p>

<p>Abstract: <em>The task of long-form question answering (LFQA) involves retrieving documents relevant to a given question and using them to generate a paragraph-length answer. While many models have recently been proposed for LFQA, we show in this paper that the task formulation raises fundamental challenges regarding evaluation and dataset creation that currently preclude meaningful modeling progress. To demonstrate these challenges, we first design a new system that relies on sparse attention and contrastive retriever learning to achieve state-of-the-art performance on the ELI5 LFQA dataset. While our system tops the public leaderboard, a detailed analysis reveals several troubling trends: (1) our system’s generated answers are not actually grounded in the documents that it retrieves; (2) ELI5 contains significant train / test overlap, as at least 81% of ELI5 validation questions occur in paraphrased form in the training set; (3) ROUGE-L is not an informative metric of generated answer quality and can be easily gamed; and (4) human evaluations used for other text generation tasks are unreliable for LFQA. We provide suggestions to mitigate each of these issues, which we hope will lead to more rigorous LFQA research and meaningful progress in the future.</em></p>

<p><strong>arXiv</strong>: <a href="https://arxiv.org/abs/2103.06332">https://arxiv.org/abs/2103.06332</a><br />
<strong>blogpost</strong>: <a href="https://ai.googleblog.com/2021/03/progress-and-challenges-in-long-form.html">https://ai.googleblog.com/2021/03/progress-and-challenges-in-long-form.html</a><br />
<strong>slides</strong>: <a href="https://docs.google.com/presentation/d/1kkl0fGbhEqWnUDkcSbFsDWIKnojlR_HFiCvhAhXW2Uk/edit?usp=sharing">https://docs.google.com/presentation/d/1kkl0fGbhEqWnUDkcSbFsDWIKnojlR_HFiCvhAhXW2Uk/edit?usp=sharing</a><br />
<strong>tweet</strong>: <a href="https://twitter.com/kalpeshk2011/status/1374443466537639939">https://twitter.com/kalpeshk2011/status/1374443466537639939</a><br />
<strong>video</strong>: <a href="https://drive.google.com/file/d/1OnArDF9tUsjDM29CI7seCbtnsCWnOkVg/view?usp=sharing">https://drive.google.com/file/d/1OnArDF9tUsjDM29CI7seCbtnsCWnOkVg/view?usp=sharing</a></p>

<p><strong>original Routing Transformer codebase</strong>: <a href="https://github.com/google-research/google-research/tree/master/routing_transformer">https://github.com/google-research/google-research/tree/master/routing_transformer</a></p>

<p><strong>code</strong>: <a href="https://github.com/martiansideofthemoon/hurdles-longform-qa">https://github.com/martiansideofthemoon/hurdles-longform-qa</a> (<em>currently only has generated outputs from model using c-REALM retrievals and random retrievals, scripts to compute ROUGE-L/R-Prec scores using generations, scripts for question paraphrase classification, scripts for ROUGE-L bounds. Hope to release pretrained models too by July/August 2021.</em>)</p>

<p><strong>external summaries</strong>: <a href="https://newsletter.ruder.io/issues/eacl-iclr-naacl-papers-round-up-research-reality-checks-ml-on-code-592784">Ruder’s newsletter</a>, <a href="https://www.youtube.com/watch?v=StyE5noPe4g&amp;t=2839s&amp;ab_channel=HenryAILabs">video1</a>, <a href="https://www.youtube.com/watch?v=8tZZoX5ct0I&amp;t=2937s&amp;ab_channel=HenryAILabs">video2</a>, <a href="https://venturebeat.com/2021/03/17/language-models-struggle-to-answer-questions-without-paraphrasing-training-data/">VentureBeat</a>, <a href="https://www.searchenginejournal.com/long-form-question-answering/402519/#close">SearchEngineJournal</a>, <a href="https://www.marktechpost.com/2021/03/27/google-ai-introduces-a-new-system-for-open-domain-long-form-question-answering-lfqa/">MarkTechPost</a>, <a href="https://techstory.in/google-ai-introduces-a-new-system-for-open-domain-long-form-question-answering-lfqa/">TechStory</a></p>
:ET