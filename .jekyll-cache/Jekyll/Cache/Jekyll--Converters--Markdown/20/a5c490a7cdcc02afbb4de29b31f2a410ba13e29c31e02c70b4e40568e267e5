I"<p>Through this blogpost I attempt to summarise the key ideas highlighted in an <a href="http://www.iclr.cc/doku.php?id=ICLR2017:main&amp;redirect=1">ICLR-2017</a> accepted paper, Frustratingly Short Attention Spans in Neural Language Modelling, (read it <a href="https://arxiv.org/abs/1702.04521">here</a>), by <a href="https://www.linkedin.com/in/michaldaniluk91/?ppe=1">Daniluk</a> et al, of the University College London. You can read the official ICLR reviews on <a href="https://openreview.net/forum?id=ByIAPUcee">OpenReview</a>.</p>
:ET